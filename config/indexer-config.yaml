# Configuration for the file indexer

# =============================================
# Async Worker Setup Instructions
# =============================================
# To use async checksum calculation:
# 1. Set checksum_mode: "async" in this config
# 2. Start the Redis server and worker process:
#    ./venv/bin/python3 -m fs_indexer.run_checksum_worker
# 3. In another terminal, run the main indexer:
#    ./venv/bin/python3 -m fs_indexer.main
#
# The worker will:
# - Calculate checksums in the background
# - Update the database automatically
# - Handle Redis connection and recovery
# - Process files in batches for efficiency
#
# Monitor the worker logs for progress and any errors
# =============================================

# LucidLink Filespace configuration
lucidlink_filespace:
  enabled: true
  port: 9778  # Port for the LucidLink Filespace API

# =============================================

# Root path to start indexing from (optional, can be provided via --root-path argument)
root_path: "<YOUR_ROOT_PATH_HERE>"

# =============================================
# OpenSearch configuration
# =============================================
opensearch:
  host: "localhost"
  port: 9200
  username: "admin"
  password: "Rollerton2020!"

# =============================================
# Database configuration
# =============================================
database:
  connection:
    url: "duckdb:///data/fs_index.duckdb"
    options:
      memory_limit: "85%"
      threads: 16
      temp_directory: "./.tmp"
      checkpoint_on_shutdown: true
      compression: "lz4"

# =============================================
# Performance tuning
# =============================================
performance:
  # Database settings
  batch_size: 100000
  db_pool_size: 1
  db_max_overflow: 0
  read_buffer_size: 268435456
  max_workers: 16
  
  # Memory settings
  mmap_size: 2147483648
  
  # File scanning
  scan_chunk_size: 20000
  parallel_scan: true
  
  # Query optimization
  enable_parallel_scan: false
  vacuum_threshold: 10000
  stats_update_frequency: 5000

# =============================================
# Logging configuration
# =============================================
logging:
  # Log level options (from most to least verbose):
  # - "DEBUG": Shows file processing details, API responses, and debug info
  # - "INFO": Shows progress updates, batch processing, and summary stats
  # - "WARNING": Shows when some files in a batch couldn't be processed
  # - "ERROR": Shows file access errors, API failures, and processing errors
  level: "INFO"
  file: "logs/fs-indexer.log"
  max_size_mb: 10
  backup_count: 5
  console: true

# Checksum calculation mode
# - sync: Calculate checksums immediately (slower indexing)
# - async: Queue checksums for background processing (faster indexing)
# - disabled: Skip checksum calculation
checksum_mode: disabled

# Redis configuration for async operations
redis:
  host: localhost
  port: 16379
  db: 0
  checksum_key_prefix: fs_indexer:checksum
  checksum_ttl: 86400
  worker:
    batch_size: 100
    retry_interval: 1
    max_retries: 5

# Check and remove database records for files that no longer exist
check_missing_files: true

# Skip patterns for file extensions and specific files
skip_patterns:
  extensions:
    - ".DS_Store"
    - ".git"
    - ".gitignore"
    - ".svn"
    - ".hg"
    - ".idea"
    - "__pycache__"
    - "*.pyc"
    - "*.pyo"
    - "*.pyd"
    - "*.so"
    - "*.dylib"
    - "*.dll"
    - "*.class"
    - "*.o"
    - "*.obj"
  
  directories:
    - .git
    - .venv
    - env
    - .env
    - .lucid_audit
    - "Godzilla_10K_tif"
    - "Godzilla_2K"
    - "test_files"
    - "00_Media"
    # - "Adobe_MAX"